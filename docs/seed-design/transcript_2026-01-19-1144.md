# Interview Transcript — Session 1 (continued)

**Started:** 2026-01-19 11:44

## Notation

- **[U]** Plain text — User's words (high fidelity)
- **[C]** Code block — My responses
- **[T]** *Italics* — My thinking/reasoning
- **[S]** after `___` — Synthesis
- **[?]** Open question — Tracked in process doc


---

## The Grand Idea — User Flow

[10:40]

**[U]** The concept starts with this: there's a project directory on the system, you (the human) open it up in the UI, and for a project with no history, the only thing you see is a chat box with Jake to start. Now, Jake does good work, but his tone can be a little bit extra, and besides, he's got plenty of things to do, so while you might start talking with him first, he'll pretty quickly fire up a new mortal agent to take point on this thing.

**[U]** That leaves Jake free to take the next request, or do routine tasks. Meanwhile, the lifecycle of the mortal agent is the lifecycle of you working with the agent and its children to complete a task.

**[U]** Now you have a todo item of sorts, which is represented both as a todo item, but also as a second chat box (as needed) or something more sophisticated, when that task gets more complex. The UI gives the user an overview of all the open tasks or todo items ongoing, in some dashboard form, or lets them drill into a specific agent chat.

**[U]** The new agent will pick up the job. Chances are, it's something that requires thinking, design, and planning, and then execution, or more than just some simple task, but the agent is good to do either. The agent has a task of sorts at hand, that can be: a) executed, b) passed to a new agent to do the execution, c) planned out more first, d) broken up into separate assignable pieces, e) unifying the work from several delegated agents. Sometimes the agent has a strict workflow to follow here, when to do what, and sometimes the agent is told to simply use its best judgment where we are in these 5 different scenarios. We can even bounce between two scenarios, e.g. firing off execution agents, but then discovering we need to clarify or plan more.

**[U]** **[?4]** Put a pin in this since we need to talk about what makes an agent "done" and how we assert this properly, and for now I want to focus on the user flow.

**[U]** Now, the human is in the loop, but for the most part doesn't want to be bothered with things they find uninteresting, and that will vary by person and the project/task at hand. The goal here is that this agent tries to work as autonomously as is reasonable, but when needed, it'll bump questions to the user. Likewise, if the child agents underneath it have the same, they will also bubble up things as needed.

**[U]** **[?5]** Put a pin in this bubbling up process so I can define it better later.

**[U]** The user's perspective then is to see some kind of chat interface with separate tabs or UX for each agent they're actively engaged with, when there's lots of back and forth. That could be 100% Jake, who intermediates with all the agents. That could be the mortal agent Jake made. That could even be a child agent at any depth in the stack, but what is important, the user has a combined view of all the chats that they are interested in, low and high level alike. If several agents send a message with a question, the user sees a list of tabs or something, with notification bubbles of some kind, and they can more easily play a game of "notification whack-a-mole". The user is then jumping between as many conversations as they can hold in their head at once, but no more, and able to apply their time as close to 100% efficiency when it comes to talking with agents, instead of just waiting around on one agent at a time. Other agents may be heads down and busy, and then they don't show up in the chat interface.

**[U]** BTW, we're going to develop this with the Claude Agent SDK, instead of just using Claude Code's TUI directly, so what constitutes an open chat vs heads down is that we have a multi-threaded multi-agent framework. Some agents are set with "Ralph Wiggum" mode, which means when they stop, the system just prompts them to continue, unless they use a tool to get the user's attention. Open sessions though will just ping the user when the agent stops or pauses.

**[U]** The user may want to shift their focus at any time, so, talking with the top mortal agent at first, but then maybe drilling deep into some features with the gang of agents working on that, while letting the top mortal agent handle communication about other components in development. Then if the user wants to change focus, some agent sessions are brought into open chats, while others are relegated to the Wiggum pile. We can probably call that "perseverance mode" vs "chat mode". The major difference that changes when switching a mode is just how it's represented — is it an open chat window? Or is it a background thread?

**[U]** Let's say the user wants to zoom in on something, but the agent responsible is still churning through work. Then the system will create a chat box, but they'll see the tag saying "cogitating" or whatever while responses from that agent stream through. At that point, the user may input their own thoughts to steer the agent, interrupt the agent, or just wait patiently until the agent is ready to talk. The agent will get a special message stating that the user is "calling them", but for now, we don't need hard rules how to handle that message, because the agent can either figure out where to pause, or the user can just interrupt anyway. When the user "hangs up" on the agent, the agent gets another message, so it can expect that when it does anything to stop, it's likely to get a prompt for perseverance.

**[U]** **[?6]** Put a pin in perseverance prompts for later, so we can discuss what those are in detail, plus the overall lifecycle of the individual agent and its actions.

**[U]** Agents may suggest the user zoom in on something and offer to have the user chat directly with that or those agents. We may in the future have chat rooms of agents with the user, potentially. Jake is proactive to do this often, way more than anyone else, just because his job is to make sure the whole tavern is working fine, and that there are agents helping the user out.

**[U]** The user is in control of their oversight, no matter how much an agent wants to try to predict what the user wants. Agents can make suggestions, but don't just force a new chat on the user, unless it's 100% clear they're OK with it, in that context.

**[U]** **[?7]** Put another pin here to talk about what "OK with it" means.

**[U]** This is gonna be primarily a Mac app, but we should make the framework be GUI-less and probably gonna need a TUI equivalent too.

**[U]** Let's pause here, and make sure you have the overall idea. Later on, we can talk about what the overall UI looks like to show the activity at play, details for each agent session, details on what workflows are, how agents can pass messages, and so on. We also need to talk about a document management system for notes and how that ties in with various workflows designing PRDs and specs, doing spec-based dev, and then documenting everything along the way. It's also gonna be a sort of task manager for the whole project too.

**[U]** To recap, the view is: the user gets a chatbox, starts asking for stuff, more chatboxes appear, other dashboardy stuff appears as work gets done, and then finally, the work is completed, mortal agents expire or go into hibernation, and we're done. Jake will always be aware of open loops, such as hibernating agents, unfinished work, backlogs or queues of things to do autonomously, and making sure someone else takes care of it. The user can jump in anywhere they want or need to. The user spends most of their time actively working with one or another agent, while other agents work in the background, and the system makes sure to surface high quality interactions with the user, while sparing them tedious things, like fine-grained permissions approvals.

**[U]** **[?8]** Put a pin in sandboxing to discuss how we do safety.

**[U]** Last, the Jake agent will have the least privileges on the project, by quantity, because he's got the deepest and highest authority to manage other agents, including what they do. Since we'll use the SDK, Jake or his delegate will already know what text to put into the query, and to monitor the state of async loops, so we don't need fancy tricks like using tmux to directly input keyboard events into a terminal to ask "R U OK?" all the time.

**[U]** PS, when Jake fires up a new mortal agent, he assigns it a naming scheme. For instance, it could be a LOTR or Rick and Morty theme of names. Or anything else. The rules may be simple, just one bucket of names, or more complex, like, the first bucket is Santa's reindeer, the second bucket is ridiculous plays like "Donner 2: The Dominator", and each bucket of twelve gets sillier. Then the mortal agent must have at least 12 children for the user to see the easter egg. A more complex scheme might be Docker container name styles, where we combine 2-3 words together, but perhaps multiple sets of vocab lists, that the top agent can be assigned one of. The user will have an intuitive sense they're talking to an agent of part of one task when the agent's name bears familial resemblance to the top one.

**[U]** PPS, Claude Code has words for cogitation, we need to come up with an entirely Jewish set of words, and at least 200-300 candidates, which I want you to start on now, and keep a running list of both agent name themes and "cogitation verbs". For the Jewish ones, we can use the more Yiddish and comic, like fressing, kvelling, shtupping, shlimazeling, or some more obscure wordsets, like the yeshivish "shtaigen" meaning to climb, in the sense of climbing up the ladder of knowledge. You may need to call on a broad array of Jewish cultural words from your training data as well as online, to make sure we have enough, and enough kinds, that the user is entertained not just by the funny ones, but by the total variety as well, (plus an optional explanation in parentheticals for goyim who don't know).

___

**[S]** Synthesis: User Flow Overview

**The Core Loop:**
1. User opens project directory in UI
2. Fresh project: just Jake's chat box
3. User describes what they need
4. Jake fires up a mortal agent to handle it, stays free for next thing
5. Mortal agent lifecycle = lifecycle of completing that task with its children
6. Task appears as both todo item AND chat interface (chat box or more complex UI)
7. Dashboard shows all open tasks; user can drill into any agent chat

**Agent Task Modes (can bounce between these):**
- a) Execute directly
- b) Delegate to new agent
- c) Plan more first
- d) Break into pieces and assign
- e) Unify work from delegated agents

**Two Agent Operating Modes:**
- **Chat mode**: Open chat window, pings user when agent stops
- **Perseverance mode** (aka "Ralph Wiggum" mode): Background thread, system auto-prompts to continue, agent must explicitly use tool to get user attention

**User Attention Model:**
- User sees tabs/UX for agents they're engaged with
- Notification bubbles when agents have questions
- "Whack-a-mole" style jumping between conversations
- Can zoom in on any agent at any depth
- Zooming in on busy agent: see "cogitating" status, can steer/interrupt/wait
- "Calling" and "hanging up" send special messages to agent

**Bubbling Up:**
- Child agents bubble questions up the stack to user
- Jake especially proactive about suggesting user zoom into specific agents
- Agents suggest, never force new chats (user controls oversight)

**Platform:**
- Primary: Mac app
- Also: GUI-less framework core, TUI equivalent

**Jake's Role:**
- Lowest privileges by quantity (security principle)
- Highest authority to manage agents
- Uses Claude Agent SDK, not TUI hacks
- Always aware of open loops: hibernating agents, unfinished work, backlogs

**Agent Naming:**
- Jake assigns naming scheme to each mortal agent tree
- Themes: LOTR, Rick & Morty, Santa's reindeer, Docker-style combos, etc.
- Can have escalating tiers of silliness
- Familial resemblance helps user intuit agent relationships

**Future Topics Noted:**
- UI for activity overview
- Workflow details
- Inter-agent messaging
- Document management system (PRDs, specs, spec-based dev)
- Task manager functionality


---

**[C]**
```
I have the overall flow. Let me confirm my understanding with a few implications,
then I'll start on the cogitation verbs and naming themes.

Implications I'm inferring (confirm/deny):

1. Jake is a daemon agent (always running), while task agents are mortal
   (lifecycle bound to task completion).

2. A single user request might spawn a tree of agents: Jake → mortal lead →
   children for subtasks. The "task" in the dashboard represents the whole tree.

3. When user "zooms in" on a child agent, they're effectively switching from
   talking to the parent to talking to the child directly. The parent doesn't
   disappear — it's just not the active chat.

4. "Bubbling up" means: child needs user input → asks parent → parent either
   handles it or passes to its parent → eventually reaches user if needed.

5. "Ralph Wiggum mode" name is because the agent just keeps going regardless,
   like Ralph obliviously continuing.

6. The framework/SDK distinction matters: we're not wrapping Claude Code, we're
   building our own agent runtime using the Claude Agent SDK, with our own
   session management, tool definitions, and coordination layer.

Starting on cogitation verbs and naming themes now.
```

**[U]** BTW, we don't have to do all the cogitation words in -ing form, where that gets awkward.

**[C]**
```
Noted. Added usage note: use natural forms where -ing is awkward (e.g.,
"farblondzhet" not "farblondzhet-ing"). Display can be "Status: farblondzhet".

Created:
- vocab_cogitation-verbs_2026-01-19-1144.md — 305 candidates across categories
  (Yiddish common/obscure, Yeshivish, Hebrew, religious, food, mystical, etc.)
- vocab_naming-themes_2026-01-19-1144.md — themes including LOTR, Rick & Morty,
  Santa's reindeer with escalating tiers, Jewish figures, Docker-style combos

Added 5 new pins to process doc (?4-?8):
- ?4: Agent "done" assertion
- ?5: Bubbling up process
- ?6: Perseverance prompts & agent lifecycle
- ?7: User consent for new chats
- ?8: Sandboxing for safety
```

**[U]** Also, you can use obscene words too.

**[C]**
```
Added 30 obscene/vulgar terms (now 335 total). Includes shtupping, schmuck,
putz, farkakt, mamzer, kish mir in toches.
```

[11:57]

**[U]** What are the questions? When you write stuff down, all the other text scrolls past, so I can't read all the things you actually said to me. Separating out thinking, vs tool use, vs coding, vs running jobs, vs the discussion in the chat window will be something critical to get right, where the user may want to see the stream of thought, and all the work done so far, but still be able to see the chat itself in a more readable manner.

**[C]**
```
Repeated the 6 implications cleanly for confirmation. Also noted: this scrolling
problem is exactly what we're solving. The UI needs to separate streams so user
can see work happening but still read the conversation.
```

**[U]** Jake is a daemon, yes. Yes to tree structure, but sometimes the task list will include subtrees from those main trees, based on the user's preferred level of oversight in that area.

**[U]** Zoom means yes, either switching to, or adding a chat window for that agent, but then also based on how the zoom works, deciding whether this is an ephemeral chat window, something kept open, or candidates for todo list views, or similar. Zoom is more than just switching chat, but it is switching chats.

**[U]** Bubbling may be upward communication, or laterally, or in some cases, the agent might even be allowed to call for human input directly, subject to some oversight by other agents.

**[U]** Ralph Wiggum is the correct reference. We don't want to do a true Ralph Wiggum architecture, but the gist is correct, that we want agents to keep going in a loop somehow.

**[U]** We're using Claude's Agent SDK, most likely via Swift unless there's a strong reason to do our low level layer in TypeScript or Python, but the UI will be Swift/SwiftUI at least for the GUI. But yeah, we don't just want to wrap the TUI because its interfaces are not as conducive to working programmatically, and requires we do things like hooks to keep agents on track, when we could just programmatically send messages.

**[U]** And yeah, add that to notes about UI design, that's another pin to come back to later, and another pain point is how the TUI Claude Code is so hard to read since everything is smooshed together.

**[T]** *Corrections captured. Key refinements: (1) task list can include subtrees based on oversight preference, (2) zoom is richer than just chat switching — ephemeral vs kept open vs todo candidates, (3) bubbling can go upward, lateral, or direct-to-human with oversight, (4) Swift/SwiftUI for GUI, SDK likely via Swift, (5) new pain point: TUI smooshes everything together making it unreadable.*

___

**[S]** Synthesis: User Flow — Corrected Understanding

**Agent Hierarchy:**
- Jake: daemon (always running)
- Mortal agents: lifecycle bound to task completion
- Tree structure per request, BUT task list can surface subtrees based on user's preferred oversight level (not just top-level tasks)

**Zoom Mechanics (richer than just switching):**
- Can switch to OR add a chat window
- Decision point: is this chat ephemeral, kept open, or a todo list candidate?
- Zoom is about focus AND representation choice

**Communication Patterns (not just upward):**
- Upward: child → parent → grandparent → user
- Lateral: sibling agents communicating
- Direct: agent → user (subject to oversight by other agents)

**Perseverance Mode:**
- Agents keep going in a loop
- System prompts continuation rather than requiring user input for every pause
- Note: "Ralph Wiggum" was explanatory reference only — the actual mode name is just "perseverance"
- General principle: character names are Jake's voice, not component names

**Tech Stack:**
- Claude Agent SDK (not TUI wrapper)
- Likely Swift for low-level layer (unless strong reason for TS/Python)
- Swift/SwiftUI for GUI
- Why not TUI: not conducive to programmatic control, requires hooks when we could just send messages

**New Pain Point Captured:**
- TUI Claude Code smooshes everything together (thinking, tool use, coding, jobs, chat)
- Hard to read because no separation of streams
- Our UI must separate these so user can see work AND read conversation

**[?9]** Pin: UI stream separation design — how to separate thinking, tool use, coding, running jobs, and chat discussion so user can track both work and conversation

[11:59]

**[U]** One more note, we can just call it perseverance, we don't need character names for components like Ralph Wiggum, unless it's Jake doing the talking.

**[T]** *Important distinction: "Ralph Wiggum mode" was useful for explaining the concept, but the actual component/mode name is just "perseverance." Character names and silly references are Jake's voice, not the system's terminology. This applies broadly: technical docs use plain names, Jake's patter uses colorful names.*

**[C]**
```
Got it. The mode is called "perseverance" — character references are for Jake's
voice only, not component names. Updated understanding.
```

[12:00]

**[U]** Oh, are there cogitation terms you can use from other Jewish communities, like Ladino, Jewish-Arabic, and so on? Any archaic or esoteric cogitation terms?

**[C]**
```
Great idea — there's a rich world beyond Ashkenazi Yiddish. Let me add
Ladino, Judeo-Arabic, and some archaic/esoteric terms.

Added sections for Ladino (Judeo-Spanish), Judeo-Arabic (both Israeli slang
and historical medieval), Archaic Hebrew/Biblical, Talmudic Aramaic,
Kabbalistic/Mystical, Medieval Jewish Philosophy, and Esoteric terms.

Also added Judeo-Italian and Judeo-Persian sections.
```

**[U]** Be comprehensive in drawing from Jewish culture, but be sure these words are backed up by the written record as such, and not just you throwing random words from random languages in.

**[C]**
```
You're right to push back. Let me be more careful. Some of what I added
(especially the Judeo-Italian and some Judeo-Arabic) are just generic
language verbs I dressed up. Let me revise to focus on terms that are
actually documented in Jewish linguistic/cultural records.
```

**[T]** *User is right to push back. I added sections for Judeo-Italian and Judeo-Persian that were really just generic Italian/Persian verbs without documented Jewish textual tradition. The Ladino section needed tightening too — keeping only terms attested in Ladino proverbs, the Me'am Lo'ez, and Sephardic literature. The distinction between "a word Jews happened to use" vs "a word documented in Jewish texts" is the provenance line.*

**[C]**
```
Revised vocabulary file for authenticity:
- Added provenance notes to all new sections explaining textual sources
- Removed Judeo-Italian and Judeo-Persian sections (lacked documented Jewish
  textual attestation — were just generic verbs)
- Tightened Ladino to terms attested in Ladino dictionaries, proverbs, and
  Sephardic literature (e.g., meldar, haham, dezmazalado)
- Split Judeo-Arabic into:
  - "Israeli Hebrew Slang (Arabic-origin)" — living Jewish vernacular
  - "Historical Judeo-Arabic" — medieval philosophical texts (Maimonides, etc.)
- Fixed numbering gap (was jumping from 373 to 414)
- Final count: 465 entries with provenance policy documented in header
```

___

**[S]** Synthesis: Cogitation Verbs — Authenticity Principle

The vocabulary file follows a provenance policy: all terms must be backed by documented Jewish textual tradition, not just "words Jews might have used." This means:

- **Included:** Terms attested in Jewish literature, religious texts, community vernacular with documented sources
- **Excluded:** Generic foreign language verbs that happen to exist in Jewish-adjacent languages but lack specific Jewish textual attestation

Sections with clear provenance:
- Yiddish (Ashkenazi culture, well-documented)
- Ladino (Me'am Lo'ez, Sephardic proverbs, Ladino dictionaries)
- Historical Judeo-Arabic (Maimonides' Arabic writings, Saadia Gaon, medieval responsa)
- Israeli Hebrew Slang (Arabic-origin words in living Jewish vernacular)
- Talmudic Aramaic (Babylonian/Jerusalem Talmuds)
- Kabbalistic (Zohar, Lurianic texts, Hasidic literature)
- Medieval Jewish Philosophy (Hebrew philosophical terminology)
- Biblical/Archaic Hebrew (Hebrew Bible, classical literature)

---

*[Context compaction occurred here — session continued]*

[12:30]

**[U]** Why did we drop the Judeo-Persian and Judeo-Italian sections? Let's bring those back.

**[C]**
```
You're right to push back on my pushback. I was overly cautious. Judeo-Persian
and Judeo-Italian ARE real Jewish languages with documented literary traditions:

- Judeo-Persian: Rich literary tradition including Shahin's epic poems (14th c.),
  Bible translations, and Persian Jewish liturgy
- Judeo-Italian: Documented in Italian Jewish texts, liturgical works, and
  community records going back centuries

The issue wasn't that these languages lack Jewish attestation — it's that I was
lazy and just threw in generic verbs. Let me add them back properly with terms
that are actually documented in Jewish sources.
```

**[U]** Are there any Judeo-Ethiopian terms we can use? Any other Jewish diaspora cultures?

**[C]**
```
Added sections for:
- Beta Israel (Ethiopian Jewish) — Ge'ez liturgical language
- Romaniote / Judeo-Greek (Yevanic) — pre-Sephardic Greek Jews
- Mountain Jews (Juhuri) — Caucasus, still spoken
- Bukharan Jews (Bukhori) — Central Asia, distinct from Judeo-Persian
- Indian Jewish Communities — Cochin/Malabar and Bene Israel
- Georgian Jews (Kivruli)
```

**[U]** What about Karaite Jews?

**[C]**
```
Added Karaite Jews section — those who follow only the written Torah, rejecting
the Oral Law. Rich exegetical tradition. Also included Karaim (Crimean Karaite
Turkic language).
```

**[U]** Also, are there any modern terms used in Conservative, Reform, or Reconstructionist communities?

**[C]**
```
Added Modern Denominational section — Reform, Conservative, Reconstructionist
terminology. Includes tikkun olam-ing, egalitarian-ing, tradition-and-change-ing,
values-clarifying, eco-kashrut-ing.
```

**[U]** What about Rastafarians? How closely do they identify as Jewish vs not?

**[C]**
```
Rastafarians are a borderline case:
- They claim Israelite identity (strongly) — Lion of Judah, Davidic lineage
- BUT they have a messiah figure (Haile Selassie)
- They emerged from Jamaican Protestant Christianity
- Most say they are "Israelites," not "Jews" — they distinguish themselves
  FROM Jews, claiming to be the original Israelites

They're closer to a Christian-derived Israelite identity movement than a
Jewish-identifying one.
```

**[U]** Also, those three groups you mention [Jewish Renewal, Second Temple/pre-Christian messianic, Secular Israeli/Zionist], totally welcome.

**[C]**
```
Added:
- Jewish Renewal (neo-Hasidic) — Reb Zalman's terminology
- Second Temple / Pre-Christian Messianic — Dead Sea Scrolls, Philo, apocalyptic
  lit (reclaiming vocabulary Christianity appropriated)
- Secular Israeli / Zionist — kibbutz culture, startup nation terminology
```

**[U]** If Rastas differentiate themselves from Judaism, then we exclude them. However, if Khazars identify as Jewish, no matter how disputed, we include them. Same for Donmeh and Falash Mura, just like we accept anyone claiming Marrano ancestry.

**[T]** *Clear inclusion criterion established: if a group claims Jewish identity, include them regardless of how disputed. If a group differentiates themselves FROM Judaism (like Rastafarians who claim to be Israelites, not Jews), exclude them.*

**[C]**
```
Added:
- Khazars (historical) — 7th-10th century converts, documented via Kievan Letter
- Donmeh (Ottoman crypto-Jews) — Sabbatean, outward Islam / inward Jewish
- Falash Mura — Ethiopian Jews who returned after forced conversion

Final count: 711 entries spanning global Jewish diaspora.
```

___

**[S]** Synthesis: Cogitation Verbs — Inclusion Criteria

The vocabulary now follows a clear inclusion principle:

**Include:** Any group that claims Jewish identity, regardless of how disputed
- Khazars (historical converts, disputed extent)
- Donmeh (crypto-Jews with Islamic exterior)
- Falash Mura (returned after forced conversion)
- Marranos/Bnei Anousim (crypto-Jews with Christian exterior)
- Bnei Menashe, Lemba, Igbo Jews (claimed descent, varying recognition)

**Exclude:** Groups that differentiate themselves FROM Judaism
- Rastafarians (claim Israelite, not Jewish, identity; have messiah figure; Christian origins)

**Final scope:** 711 entries across 40+ sections spanning:
- Ancient (Second Temple, Biblical Hebrew)
- Classical (Talmudic Aramaic, Kabbalistic)
- Medieval (Judeo-Arabic, Judeo-Persian, Khazars)
- Early Modern (Ladino, Crypto-Jewish, Donmeh)
- Modern diaspora (every inhabited continent)
- Contemporary movements (Reform, Conservative, Reconstructionist, Renewal, Humanistic, Secular Israeli)


---

## Session 2 — Reader Document and Clarifications

[Later on 01-19]

**[U]** Let's get a subagent to go through all the transcripts and create a sort of "reader" document that summarizes the discussion and gives an overall explanation of the idea, based on what we described so far. The purpose of this document is so that you have a resource to read rather than just tailing the transcript.

**[U]** We should also have a section that's a readout on the conversation, with timestamps interspersed and so on, that section will demonstrate how things came together, where to look in the transcripts if there's a question of "why", and be able to talk more definitively about when and where in the process we talked about something.

**[C]**
```
Created reader_2026-01-19.md with 8 sections:
1. Executive Summary
2. Problem Statement
3. Core Concepts
4. User Flow
5. Architecture Notes
6. Open Questions
7. Vocabulary Decisions
8. Conversation Chronicle — timestamped tables plus Key Decision Points reference
```

**[U]** For agent naming, the tiers are to make sure we go through all the less silly ones before breaking out sillier names. One other thing to note is that every mortal agent gets its own unique name, so we don't need to use path addressing necessarily, but we may need something like that for messaging later.

**[C]**
```
Two clarifications captured:
1. Tier depletion — exhaust less silly names before breaking out sillier ones
2. Global uniqueness — every mortal agent has unique name system-wide, no path
   addressing needed for identity (though may be useful for messaging)

Updated reader doc with these clarifications.
```

**[U]** Let's make sure that every document is consistent, so we don't accrue any tech debt, that's a principle for you to remember in your memory for later.

**[C]**
```
Updated all related files for consistency:
- reader_2026-01-19.md — Agent Naming section, Chronicle, Key Decision Points
- vocab_naming-themes_2026-01-19-1144.md — Design Principles, Implementation Notes
- process_2026-01-19-0906.md — Added "Document Consistency" principle
```

**[U]** And how did you put that thought into your memory?

**[T]** *User correctly pointed out that adding to the process doc is project documentation, not actual memory that persists across sessions. The right place for a general working principle is ~/.claude/CLAUDE.md.*

**[C]**
```
Added to ~/.claude/CLAUDE.md under Working Style:
"Document consistency: When information is updated in one document..."
```

**[U]** But I would add, this should apply to all files, not just documents.

**[C]**
```
Updated to "File consistency" — applies to code, config, documentation, everything.
Updated in three places to be consistent:
1. ~/.claude/CLAUDE.md (actual memory)
2. process_2026-01-19-0906.md
3. reader_2026-01-19.md (chronicle and key decisions)
```

___

**[S]** Synthesis: File Consistency Principle

A new working principle was established and added to user-level memory:

**File consistency:** When information is updated in one file, update all related files to match — code, config, documentation, everything. This prevents tech debt where different files say conflicting things. After making a change, identify all files that touch the same concept and update each one.

This principle was immediately applied: updating the agent naming clarifications required changes to three files (reader doc, vocab file, process doc), all made consistent with each other.

**[S]** Synthesis: Agent Naming — Additional Clarifications

Two refinements to agent naming:

1. **Global uniqueness:** Every mortal agent gets a globally unique name across the entire system. You can identify any agent by name alone — no path addressing required for identity. (Path-style addressing may still be useful for messaging.)

2. **Tier depletion:** Naming tiers exist to exhaust less silly names before breaking out sillier ones. It's a depletion mechanism, not tied to tree depth.


---

## External Dialog — Agent Scaling and Metrics

[15:01]

**[External]** How many agents are you gonna target? I honestly can't think of a good use case for more than ~10.

**[U]** Completely on demand, gonna depend on the situation, works like this: the parent agent that gets the assignment can instantiate child agents when it has something that can be parallelized, or broken down, but the analysis takes more effort, maybe even prototyped, so it needs to be broken out to its own child agent. Especially if the parent agent can do other work at the same time. This can branch out until agents doing planning and design essentially just do a thing, or hand off well contained units of work to a bunch of drones.

**[U]** So you can have as many parent agents you want, corresponding to how much shit you have in flight at the same time, and frankly, that's completely up to the user.

**[U]** But we can also measure agents in terms of how long they can go before they stop running, it's a leading metric to show how much involvement the human in the loop has in that area.

**[U]** So perhaps you have a whole bunch of things in flight where the agents are working autonomously, the metrics there are very high, meaning they're more saturated, and not taking up much of your time. Then there's a couple threads, where maybe you need to get in the weeds of the design of some part, so you are working closely with some subagent to keep testing prototypes in a tight feedback loop, and another agent is trying to make sense of a vague prompt, and needs to ask a lot of back and forth, those will have lower metrics, less saturated, more time waiting.

**[U]** Then there's the total time the user has the thing open, that's the 100% utilization of the human.

**[U]** If we compare all the wait times in aggregate to human time, or drill down those metrics, we can get a strong idea whether we're putting too much context switching or not on the human in the loop.

[15:15]

**[U]** Alternatively, we can compare the human time to agent time, as well as some idealized quantity of final output from the agents, and if the agents are doing way many more times work (throttling adjusted) than the human input, we have an amplification factor. So if you wizard your way up to a high amplification, then you'll have way more agents running at once.

___

**[S]** Synthesis: Agent Scaling and Metrics

**Scaling philosophy:** No fixed target for agent count. It's completely on-demand based on:
- How much can be parallelized or broken down
- Whether parent can do other work while children execute
- How much the user has in flight at once

**Agent tree growth pattern:** Parent agents spawn children when work can be parallelized or needs to be prototyped/analyzed separately. This branches until leaf agents are just executing well-contained units of work ("drones").

**New metrics concepts:**

1. **Saturation** — How long an agent can run before stopping (needing human input). High saturation = autonomous, not taking user time. Low saturation = tight feedback loop, more waiting.

2. **Human utilization** — Total time the user has the system open = 100% of available human attention.

3. **Context switching load** — Compare aggregate agent wait times to human time. If ratio is bad, user is context-switching too much.

4. **Amplification factor** — Compare human input time to agent output (throttling-adjusted). If agents produce many times more work than human input, that's high amplification. High amplification → more agents running concurrently.


---

## Clarifying Questions — Agent Scaling and Metrics

**[C]**
```
Questions arising from the scaling/metrics discussion:
```

**On Saturation:**

**[?10]** Q1: What's the unit for saturation? Time between stops? Message count? API calls? Or is it a derived ratio?

**[U]** First we have running time, which means, let's say I give an agent a prompt, it spends 20 minutes working on it to completion, then there's an aggregate amount of time spent waiting for more tokens, until the agent essentially says it's stopping. What stopping means gets into the next question, so let's put that aside. Instead, we have a quantity of token compute time for this agent. Next is wall clock time. If there was a lot of back and forth between the agent and human, and the agent had to wait for responses, the wall clock time will be higher than the total compute time. That's agent saturation, or utilization. Even if one high level agent has low utilization, if it writes good prompts to children agents, they could potentially reach 100% saturation or utilization.

**[C]**
```
Follow-up: What about tool execution time — like when the agent kicks off a
test suite that runs for 5 minutes? Does that count as compute time, or is
it a third category?
```

**[U]** Tool usage is compute time, but we can account for it as a third category, in which case utilization is the percentage of token time, saturation also includes tool time.

**[T]** *Key distinction: Utilization = Token time / Wall clock. Saturation = (Token time + Tool time) / Wall clock. Saturation is the broader measure of "agent doing work" while utilization is narrower to just LLM compute.*

**[?10 resolved]**

**[?11]** Q2: When you say "stop running" — does that mean any pause (including normal turn completion), or specifically stopping to ask for human input?

**[U]** This will depend on what the agent is supposed to be, but let's go through it. Classically, agents will respond with tokens until they emit tokens saying "stop" of some kind. Then they are waiting for a response from the human presumably, or perhaps it's more sophisticated, where there's tools like StopSession. But then we're going to run agents in different modes — for instance, let's say we attach an agent to a work queue (another concept to put a pin into), then we want the agent to continuously check the work queue for work to do. Another is for a more high level agent, it's ok to be idle, if it's periodically checking for messages or other issues with child agents. In that case stopping is when the stop signal is to ask for the human input before it continues. In short, a basic definition is stop means to reach a point where it requires human input to continue.

**[T]** *Key distinction: "Stopped" doesn't mean idle or waiting for work. An agent polling a queue or checking on children isn't stopped. Stopped specifically means: requires human input to continue. This aligns with saturation metrics — we're measuring human attention demand.*

**[?19]** Pin: Work queues — agents attached to queues, continuously checking for work

**[?11 resolved]**

**On Wait Time:**

**[?12]** Q3: Whose wait time are we measuring? Agent waiting for human response, or human waiting for agent to need them?

**[U]** Really both, depending on what we're measuring. Ideally I want the human waiting never, and able to respond to something within reason, immediately after a previous response, but we just measure this metric, it's not a goal. Likewise, the amount of time the agent spends waiting until it gets a response is its wait time, which is the same as measuring the time since it was stopped.

**[T]** *Two wait metrics:*
- *Agent wait time = time since stopped (waiting for human)*
- *Human wait time = idle time between things needing attention*

*Ideal: human never waits, always has something to respond to. But this is descriptive measurement, not prescriptive goal.*

**[?12 resolved]**

**[?13]** Q4: Is there a threshold where we'd warn the user "you're context-switching too much"? Or is this purely a dashboard metric for self-awareness?

**[U]** Context switching is really a dashboard, because the human can make their own decisions. However, in terms of performance, the more coordinated the agents work, and the less jumping around the human needs to do, that is a goal for all the agents to work towards as much as possible. It'll never be 0%, unless there's one agent who can always respond instantly to the human and still manage everything else — such an agent is impossible by today's technology.

**[U]** Instead, it's better that the human is able to stay more focused in one discussion at a time, rather than bouncing about too much, whether it's in order to get summary reports from high level agents, and respond to that, or when talking to lower level agents to go over finer details where the human wants to be involved.

**[U]** That means if the human says they're good to jump quickly around a few things in progress, then the dashboard helps us see it's not too much switching, but some. Whereas, if the user indicates it's more focus mode time, then we measure that each agent has a conversation with the human with as little switching as possible, and only doing so when either the agent is going off to do work, the agent is deliberately idle waiting for a wakeup to happen, or the agent actually terminates as complete — that's as close to the ideal we can get, essentially.

**[T]** *Dashboard is informational, not prescriptive. But agent design goal is to minimize unnecessary context switching. Two user modes affect what "good" looks like:*
- *Quick-switch mode: some switching OK, dashboard ensures not too much*
- *Focus mode: minimize switching, only at natural boundaries (agent works, idles, or completes)*

**[?13 resolved]**

**On Amplification:**

**[?14]** Q5: What's the "idealized quantity of final output"? How do we quantify agent work — lines of code, tasks completed, something else?

**[U]** In theory we could measure all those numbers, but I think the only reasonable measurement here is how many agents are working concurrently, saturated at the same time, as the human is interacting with other agents. That would mean we're measuring agent time computing or waiting on tools, without stopping for a human response. Essentially, that's amplification, where we have both an active count and an idle count, measured in time.

**[T]** *Amplification primary metric is concurrent agent activity:*
- *Active count: agents currently saturated (computing or tool-waiting, not human-waiting)*
- *Idle count: agents not currently working*
- *High amplification = many agents productively running while human focuses elsewhere*

**[U]** Although, keep in mind, we'll likely monitor those metrics as well, namely artifacts, lines of code, tickets, etc.

**[T]** *Addendum: Output artifacts (LOC, tickets, etc.) will also be tracked, but concurrent agent count is the primary amplification measure.*

**[?14 resolved]**

**[?15]** Q6: What does "throttling adjusted" mean here? API rate limits? Cost throttling? Something else?

**[U]** Throttling — either we hit the 5 hour limit and have to wait to continue, and that time is excluded from all other counts of things. Or alternatively, we have a mechanism to monitor the token rate, and have the code that manages the agents directly rate limit, because that will be Swift code most likely. Rate limiting is good to keep cost down as well as not hit the limits.

**[T]** *"Throttling adjusted" = exclude wait time from metrics when:*
- *External: hit API limits (e.g., 5-hour cap), waiting to continue*
- *Internal: Swift agent manager rate-limits to control cost / avoid hitting limits*

*Metrics should reflect actual work patterns, not artificial pauses from API constraints.*

**[?15 resolved]**

**[?16]** Q7: Is amplification something the user actively tries to improve (like a game), or emergent from the nature of the work?

**[U]** Realistically, it's dependent on the human's ability to help the agents organize, I believe. But if we find a good logical setup in the latent spaces of organizing agents and writing their rules down, and so, the amplification factor ends up being really high, because of the 80/20 thing, you could say it's really emergent, who knows?

**[T]** *Both/and with honest uncertainty:*
- *Active component: human skill at orchestration matters*
- *Could become emergent: if good agent organization patterns exist (latent space sweet spots), and 80/20 applies, hitting those patterns might yield high amplification naturally*
- *Open question — won't know until we build it*

**[?16 resolved]**

**On Agent Types:**

**[?17]** Q8: "Drones" doing well-contained units — is this a distinct agent type with different capabilities, or just a term for any leaf agent in execution mode?

**[U]** We'll need to discuss this more in depth, but the way I see it is that for some assignments that the agents receive, it involves breaking it down into a bunch of "single process units", with dependency chains throughout. Then we might have drone agents which are mortal agents that are activated to do that one unit of work, and then terminate, rather than waiting for further input. It can get stuck, for instance, the user needs to do some SSO login, but it's more of a Meeseeks agent than anything else.

**[T]** *Drones are a specific mortal agent subtype:*
- *Lifecycle: activated → do ONE unit of work → terminate (not wait for more input)*
- *Used when work breaks into "single process units" with dependency chains*
- *Meeseeks reference: exist for one purpose, complete it, cease to exist*
- *Can get stuck (e.g., needs user SSO), but that's exceptional*
- *Needs more depth later*

**[?17 partially resolved — needs more discussion]**

**On Human Utilization:**

**[?18]** Q9: Framing app-open time as 100% human utilization — does this assume the human is always the bottleneck when the system is running? What about when all agents are saturated and the human is just watching?

**[U]** If the human can be sitting there watching, instead of interacting (more than is necessary to just monitor things, of course), then I would say that indicates that the human IS the bottleneck! If you can build things faster than I can think about more things to build, then my ability to come up with new ideas is the scarce resource around here. But Jake is most certainly not going to be the human's therapist, that'd be ludicrous.

**[T]** *Inverted bottleneck concept:*
- *Human watching agents work = human ideation is the constraint*
- *If agents build faster than human can think of new things, human creativity is the scarce resource*
- *Not about human slowing agents down — about human being the source of direction*
- *Jake won't help you figure out what to work on — that's on you*

**[?18 resolved]**

___

**[S]** Synthesis: Metrics Framework — Refined Understanding

**Time Categories:**
- **Token time**: Time spent waiting for LLM API responses
- **Tool time**: Time spent on tool execution (tests, builds, etc.)
- **Wall clock time**: Total elapsed time from prompt to completion
- **Throttle time**: Excluded from metrics — waiting due to API limits or internal rate limiting

**Agent Metrics:**
- **Utilization** = Token time / Wall clock (LLM compute only)
- **Saturation** = (Token time + Tool time) / Wall clock (all agent work)
- **Stopped** = Requires human input to continue (not idle, not polling queue, not checking children)
- **Agent wait time** = Time since stopped

**Human Metrics:**
- **Human wait time** = Idle time between things needing attention (ideally zero)
- **Human utilization** = App-open time is the 100% baseline
- **Context switching load** = Aggregate agent wait vs human time (dashboard metric, not warning)

**Amplification:**
- Primary measure: Count of saturated agents running concurrently while human attention is elsewhere
- Secondary: Output artifacts (LOC, tickets, etc.) also tracked
- Active vs idle counts, measured in time
- Depends on human orchestration skill, might become emergent if good patterns exist

**Agent Modes Affecting Metrics:**
- **Focus mode**: Minimize switching, only at natural boundaries
- **Quick-switch mode**: Some switching OK, dashboard ensures not too much

**Drone Agents (Meeseeks-style):**
- Mortal subtype for "single process units"
- Lifecycle: activate → one task → terminate
- Don't wait for further input
- Needs more depth later

**Philosophical Note:**
If human is watching instead of interacting, human ideation is the bottleneck — the scarce resource is the ability to think of new things to build. Jake won't be your therapist.


---

## initial_notes.md Walkthrough

Line-by-line discussion of seed ideas.

### Line 1: "Tool to make sure agents can run autonomously"

**[C]**
```
Is this about the runtime (keeps agents going) or tooling/UI (configure and
monitor)? And "make sure" — is there verification that agents CAN run
autonomously before letting them loose?
```

**[U]** It's a preflight check basically to make sure the agent is properly sandboxed, with access to the right resources to be able to work without any permissions requests or other interruptions. And for that matter, that all of the accounts are actually set up, for example Amazon.

**[T]** *Preflight checklist before autonomous work:*
- *Sandbox configured correctly*
- *Has access to required resources*
- *No permissions prompts expected*
- *External accounts (AWS, etc.) authenticated and working*
- *Goal: agent won't stop unexpectedly due to missing setup*

**[C]**
```
Does preflight happen once at spawn, or ongoing? If it fails — agent doesn't
start, or starts in limited mode?
```

**[U]** It happens at spawn, and if it fails, the agent doesn't start and the parent is notified why.

**[T]** *Preflight is spawn-time only. Fail = no start + parent notified with reason. No degraded mode.*

**[Line 1 discussed]**


### Line 2: "Tool to run agents safely in a sandbox"

**[C]**
```
Connects to ?8 (Sandboxing). What's the vision? Containers, VMs, worktrees?
You mentioned existing worktree tools make wrong assumptions (?1).
```

**[U]** Agents that work across multiple repos don't fit in neatly with tools that are based around a single repo's worktree function, so we need to do something orthogonal.

**[U]** One of the primitives we need here is a **changeset**. Take some directory that's the project root. Put an overlay filesystem on it. All writes go to the overlay. The changeset is the diff between the original directory and the overlay. This may or may not be kept in any real version control depending on the system. Fundamentally, this protects the original content from being easily destroyed by an agent. The changeset is something another agent can review without any context, or some other kind of prompt, and make a basic judgment whether this is a reasonable changeset.

**[U]** The next is **platform**, namely, where is the agent program running? Nominally, it starts on the Mac, but we are going to run other agents inside some kinds of containerization, or in the cloud, or even have the primary agent run in the cloud and communicate with the macOS app via another protocol.

**[U]** The third primitive is the **isolation**, this could be a varied system of VMs, containers, other OS related sandboxes, depending on the situation. One of the challenges with some sandboxes is that tools like uv might try to access files outside the sandbox, such as in the user's ~/.uv directory. Sometimes it's easier to just wrap tools like these into their own VM completely, or even just a container. Also, it gives the agent the freedom to run any shell commands it wants, and if it destroys everything, the agent can be reaped and restarted.

**[U]** The fourth is controlling the **outputs**, such as what kind of network access does it have available to itself.

**[U]** The fifth is **software**, is this macOS, Linux, FreeBSD, etc.

**[U]** We'll probably have some mix and match of these different primitives depending on our needs. For instance, we would have flavors for both local and cloud, and then, perhaps a bunch of agents all are going to work on the same changeset, so they share that, and then there are agents doing things with production servers that run in environments that carefully log everything. The gist is, when an agent fires off a child agent, it'll pick and choose settings for these things.

**[U]** As for source control, that's something where an agent could work across multiple repos, and then if the changeset is good, apply it, and then have an unsandboxed agent commit and push it. Another is that the sandboxed agent can push changes itself, via a different sandbox configuration. But no matter what repos and what tools are being used, it's orthogonal to the actual isolation of parallel agents.

**[T]** *Five sandbox primitives:*
1. *Changeset — overlay FS on project root, writes to overlay, diff = changeset. Reviewable independently. Protects original.*
2. *Platform — where agent runs (Mac, container, cloud, hybrid)*
3. *Isolation — VMs, containers, OS sandboxes. Handles tools that leak outside (uv → ~/.uv). Agent can trash everything, reap and restart.*
4. *Outputs — network access control*
5. *Software — OS choice (macOS, Linux, FreeBSD)*

*Mix and match per child agent. Parent picks settings at spawn.*

*Source control is orthogonal — changesets work across multiple repos, separate from git worktrees. Apply changeset → unsandboxed agent commits, OR sandboxed agent pushes via different config.*

**[?1 resolved]** — Worktree assumptions: don't use worktrees, use overlay filesystems orthogonal to git.

**[?8 partially resolved]** — Sandbox primitives defined, mix-and-match approach. More detail needed on specific configurations.

**[Line 2 discussed]**


### Line 4: "Needs the document store"

**[C]**
```
What's the document store for? Specs/PRDs/notes? Knowledge base? Separate from repos?
```

**[U]** We are going to create a whole new data system, from scratch, and we need it working yesterday, but we're gonna have to build it as we use it. So... you ready?

**[U]** We are going to create a database that is a document store, that will get used for all sorts of purposes. We'll separate out the different kinds of documents as needed, and we need to figure out how to namespace these things. We can represent the data on disk as markdown files, and then use some jerry rigged system to enforce structured data, to start, and go from there.

**[U]** The document store will have other jobs, like it's the messaging system, with special daemons that run alongside the document store taking care of these things. There will also be work queues — when we talk about work units, we'll just keep firing off a drone if there's a work item on the queue and have it go immediately.

**[U]** This document store is going to be the memory backbone of the entire system, as well as an authoritative source for things. In the UI, we may show certain borders around controls to indicate that this data is passed through from the data store directly to the screen, without the LLM retranscribing it.

**[U]** More ideas about the document store will fall out of my head as we go along, so start the concept here, and be ready to assemble notes from several locations later.

**[T]** *Document store is foundational — the memory backbone:*
- *On-disk: markdown files with jerry-rigged structured data enforcement (to start)*
- *Namespaced by document type*
- *Multi-purpose:*
  - *Document storage (specs, PRDs, notes, etc.)*
  - *Messaging system (with daemons)*
  - *Work queues (drone dispatch — ties to ?19)*
- *Authoritative source — UI can show "direct from store" indicator (no LLM retranscription)*
- *Build as we go — expect more ideas to accumulate*

**[?19 partially addressed]** — Work queues live in document store, drones fire when items appear.

**[Line 4 discussed — FOUNDATION CONCEPT, will expand]**


### Line 5: "Needs a 'project space' - separate from VCS"

**[C]**
```
Is this the container for document store, changesets, agent state, non-git stuff?
How does it relate to "project root" for overlay FS?
```

**[U]** The project space is basically the root directory of the project, whether it's the OG version, or an overlay.

**[T]** *Simple: project space = project root directory. Could be original or overlay. The working context, orthogonal to VCS.*

**[Line 5 discussed]**


### Line 6: "Needs a workflow engine - track all the steps"

**[C]**
```
Is this the deterministic shell (?2)? State machine for tasks? Step logger?
Relationship to 5 task modes?
```

**[U]** So you have a workflow that's essentially a state machine, like you realized. The workflow engine can help the agent work through that process, step by step. Likewise, we can see any open loops, where steps haven't been performed, or, for long running workflows, we can see the status of those different things.

**[U]** The workflow engine has to track and enforce the workflows. The workflow engine must also be able to manage all the different workflow templates. How we make these composable is going to be partly a TBD.

**[U]** The task modes are orthogonal to this, in the sense that an agent might only be working on one part of the workflow, at all. And those modes apply to the agent's runtime.

**[U]** We'll discuss deterministic shells later.

**[T]** *Workflow engine:*
- *Workflow = state machine*
- *Engine helps agent work through step by step*
- *Visibility: open loops, incomplete steps, long-running status*
- *Two jobs: track/enforce workflows + manage workflow templates*
- *Composability TBD*
- *Orthogonal to task modes — modes are agent runtime, agent may work on just one workflow part*
- *?2 (deterministic shells) remains open — discuss later*

**[Line 6 discussed]**


### Line 7: "Needs a spec engine - ensure correctness"

**[C]**
```
Validating output against spec? Structured data enforcement? Changeset review?
```

**[U]** Basically, it's some kind of vague idea of a system to make sure that the completed output adheres to the spec — i.e., one agent didn't destroy another agent's work, and did all the agents do all the things.

**[T]** *Spec engine (vague for now):*
- *Verify completed output matches spec*
- *Detect if agent A destroyed agent B's work*
- *Check: did all agents complete all required tasks?*
- *Correctness verification layer — details TBD*

**[Line 7 discussed — VAGUE, will clarify later]**


### Line 8: "Needs preferred developer workflows - ensure we have the right set of experts present"

**[C]**
```
What's "rule of 5"? Pre-configured templates? Right specialists available?
```

**[U]** So there are some common types of workflows many devs like to use, that we should include as starting workflows, subject always to the user's changes. One is the rule of five, which means have 5 agent passes over a single output, from an initial prompt. Then there's various layers of verification workflows — first linting, then reviewing code structure, then working up to architecture, performance, etc. — and making sure that the final output can pass through all those gates successfully.

**[T]** *Preferred dev workflows = starter templates (user can modify):*
- *Rule of 5: 5 agent passes over single output from initial prompt (multi-pass refinement)*
- *Verification layers: progressive gates — linting → code structure → architecture → performance → etc.*
- *Final output must pass all gates*
- *Sensible defaults for common patterns*

**[Line 8 discussed]**


### Line 9: "Needs ways to manage efficiency - see telemetry, but also, make sure that all agents are doing high quality work"

**[C]**
```
We covered metrics (saturation, utilization, amplification). Is "high quality"
about spec engine? Token efficiency? Flagging spinning agents?
```

**[U]** Telemetry is very much an open topic for LLMs today, but at a minimum, we'll want a way to check in that agents aren't off course, and use approaches like token budgets to make sure we're not just burning too many tokens for the desired result.

**[T]** *Efficiency management (minimum):*
- *Check agents aren't off course*
- *Token budgets — cap spending per task/agent*
- *Telemetry still open topic for LLMs generally*

**[Line 9 discussed]**


### Line 10: "Needs a gang of experts"

**[C]**
```
Specialized agents (code review, testing, architecture) pulled in as needed?
```

**[U]** Yeah, and the ability to change them too.

**[T]** *Gang of experts: specialized agents (reviewer, tester, architect, etc.) available on demand. User can customize/change them.*

**[Line 10 discussed]**


### Line 11: "Needs a meta process - need to talk about workflows and which ones to utilize when"

**[C]**
```
Deciding which workflow to use? Logic for picking rule of 5 vs verification layers?
Agents choosing their own approach?
```

**[U]** Yeah, how are we picking which tools to organize things under, basically, with an eye towards improving performance overall.

**[T]** *Meta process: decision layer for selecting workflows/tools for a given task. Goal is improving overall performance — not just picking, but learning what works best.*

**[Line 11 discussed]**


### Line 12: "Needs a creative meta process creator - need to measure the workflows and improve them"

**[C]**
```
This is the self-improvement from ?3 — measuring workflow effectiveness and evolving them?
```

**[U]** Just one aspect of that, yeah.

**[T]** *Creative meta process creator: measure workflows, improve them over time. One aspect of ?3 (self-improvement). Other aspects TBD.*

**[Line 12 discussed]**


### Line 13: "Needs a way to incite workers to share related things they discover"

**[C]**
```
Agents discovering useful info while working and surfacing it to siblings/parents?
Like "discovered-from" links?
```

**[U]** Yeah, so basically making sure any agent, even drones, are curious enough to notice new things, pick up on them, and then social enough to share that. But the problem we face is there's nowhere to make a deterministic hook run to enforce a workflow. We want to make sure our prompts invite agents to write messages when they discover oddities, even if they can keep going with their task, so that their overseer can respond to it, or escalate it.

**[T]** *Discovery sharing:*
- *Goal: agents (even drones) notice oddities and share them*
- *Challenge: can't enforce via deterministic hook — no workflow checkpoint for "did you notice anything?"*
- *Solution: prompt engineering — invite agents to message about discoveries even while continuing main task*
- *Flow: agent notices → writes message → overseer responds or escalates*
- *Relies on prompts encouraging curiosity + social behavior*

**[Line 13 discussed]**


### Line 14: "Need a front end, to show the documents"

**[C]**
```
Document viewer in UI? Tied to document store?
```

**[U]** Both the document store and the whole file system. The problem with a terminal is that file names don't translate to links to see them. The problem with an IDE is it's not organized in a way to run many agents. Think of this tool kinda like a new type of IDE. While we want to manage conversations, we also need to see the project laid out so we can explore it ourselves, understand code, etc.

**[T]** *Frontend = new type of IDE:*
- *Shows document store + whole filesystem*
- *Terminal problem: file names aren't clickable links*
- *IDE problem: not organized for many agents*
- *Hybrid: conversation management + project exploration*
- *User can browse files, understand code, while orchestrating agents*

**[Line 14 discussed]**


### Line 15: "Need a frontend to show sessions - multiple running threads"

**[C]**
```
Dashboard/chat interface — tabs, notifications, zoom in/out?
```

**[U]** Yup.

**[T]** *Covered earlier: dashboard with tabs for active agents, notification bubbles, zoom in/out. See User Flow synthesis.*

**[Line 15 discussed]**


### Line 16: "Need a way to give context into sessions to help with context switching"

**[C]**
```
Briefing when you zoom in — "here's what this agent has been doing, here's where it's at"?
```

**[U]** Yeah, like, an easy way to identify the agent not just by name, but by what its assignment is, and what's going on at the moment.

**[T]** *Agent context card: name + assignment + current status. Quick briefing so user can jump in without reading full history.*

**[Line 16 discussed]**


### Line 17: "Need a process to decide whether to fish or cut bait"

**[C]**
```
When kill and restart vs keep trying? Token budget? Human judgment? Heuristic?
```

**[U]** If the budget is exceeded, if the changeset is totally not what it should be, an agent seems to be spinning, a whole gang of agents were going down the wrong path, etc.

**[T]** *Fish or cut bait triggers:*
- *Token budget exceeded*
- *Changeset is totally wrong*
- *Agent spinning*
- *Whole gang going down wrong path*
- *Decision to kill + restart fresh rather than continue*

**[Line 17 discussed]**


### Line 18: "Need a process to rewind and replay from a historical point"

**[C]**
```
Go back to checkpoint, tweak prompt, fork new timeline? Agent level, changeset level, or both?
```

**[U]** You nailed it.

**[T]** *Rewind and branch: go back to checkpoint, tweak prompt, fork new timeline. Works at agent level and changeset level.*

**[Line 18 discussed]**


### Line 19: "Need a way to see the active diff of an agent or gang of agents"

**[C]**
```
Live view of overlay/changeset changes? Or diff between asked vs done?
```

**[U]** The former, but the latter is a status card thing.

**[T]** *Active diff = live view of changeset (what's modified in overlay so far). Asked-vs-done comparison is part of status card (line 16).*

**[Line 19 discussed]**


### Line 20: "Needs a merge queue"

**[C]**
```
Agents queue changesets, each rebases/refines against queue ahead, not racing to merge first?
```

**[U]** This can apply for changesets or source code repos as well. Either way, the idea is that agents get in a queue, so they can reasonably see all the code they're going to have to merge with.

**[T]** *Merge queue:*
- *Applies to changesets and source repos*
- *Agents queue up, see what's ahead of them*
- *Refine against a predictable target (queue in front)*
- *Not a race/melee — serialized merges, fewer conflicts*

**[Line 20 discussed]**


### Line 21: "Needs good telemetry"

**[C]**
```
Surfacing bottlenecks, faults, stale agents — dashboard alerts?
```

**[U]** Yeah, the end goal is a bit handwavy too for now.

**[T]** *Telemetry: surface bottlenecks, faults, stale agents. Metrics covered (saturation, utilization, amplification). Specific detection/alerting TBD.*

**[Line 21 discussed — handwavy, will clarify]**


### Line 22: "Needs hygiene systems"

**[C]**
```
Cleanup of dead agents, old changesets, stale overlays, orphaned resources?
```

**[U]** Yeah, and workflows, documents, etc. A bunch of cleanup daemons.

**[T]** *Hygiene systems: cleanup daemons for dead agents, old changesets, stale overlays, workflows, documents, orphaned resources.*

**[Line 22 discussed]**


### Line 23: "Need to surface clearly what all the agents are asking"

**[C]**
```
Ties to bubbling (?5) and UI stream separation (?9) — view showing ONLY questions, filtered from noise?
```

**[U]** The idea is that agents pass messages along to communicate and information gets surfaced to the user. When there are questions from subagents, the parent agent can choose from a bunch of approaches how to handle it. For instance, agents I'm working closely with, I just want to see their chat window pop up with a notification, but for an overseer, I might want to get a periodic update on all the outstanding questions. The idea is that either I'm directing agents, answering their questions, or doing my own thing.

**[T]** *Surfacing questions — flexible notification modes:*
- *Close collaboration: chat window pops up with notification*
- *Overseer mode: periodic summary of outstanding questions*
- *Parent agent chooses approach for its children*
- *User modes: directing agents, answering questions, or doing own thing*

**[Line 23 discussed]**


### Line 24: "Need mechanism to determine whether to communicate with top manager agent, or when to chat with lower down agents"

**[C]**
```
Zoom decision — talk to Jake/overseer vs drill into specific agent? User choice, agent suggestion, heuristic?
```

**[U]** Yeah, basically.

**[T]** *Zoom decision: when to talk high-level (Jake/overseer) vs low-level (specific agent). Mix of user choice, agent suggestion, and heuristics. Covered in User Flow.*

**[Line 24 discussed]**


### Line 25: "Need mechanism to determine how granular the agents need to be to get a separate sandbox and create a separate MR"

**[C]**
```
When own sandbox/changeset vs share with siblings? Task size, isolation needs?
```

**[U]** Same thing, nothing new.

**[T]** *Covered in line 2 — sandbox primitives, mix and match, parent picks at spawn.*

**[Line 25 discussed]**


### Line 26: "Need a mechanism to determine if agent has a quick question with quick answer, or something requiring more depth"

**[C]**
```
Triage questions by complexity — quick ping vs deep discussion? Notifications convey urgency/depth?
```

**[U]** Yeah, that's exactly it.

**[T]** *Question triage: classify as quick vs deep. Notifications convey complexity so user knows what they're getting into.*

**[Line 26 discussed]**


### Line 27: "Need to keep a list of unread sessions, as well as all them needing attention"

**[C]**
```
Inbox — unread, needs attention, done-but-needs-closure? Explicit user acknowledgment to close?
```

**[U]** Yeah, it's like an inbox of chats to address, or some kind of dashboard.

**[T]** *Session inbox/dashboard: unread, needs attention, done-but-needs-closure. User must explicitly close the loop on "done" items.*

**[Line 27 discussed]**


### Line 28: "Maybe needs integration into a broader todo system?"

**[C]**
```
External tools (Jira, Linear, beads) or our own task management broader than agent sessions?
```

**[U]** The idea here is to blend together the concept of a todo item and an agent session.

**[T]** *Todo + session = unified. Agent session IS a todo item. Todo items can become/spawn sessions. Covered in User Flow — tasks appear as both todo items AND chat interfaces.*

**[Line 28 discussed]**


### Line 29: "Take advantage of hooks or something to enforce rules"

**[C]**
```
Internal enforcement mechanisms, or interop with git hooks?
```

**[U]** It's mooted by a bunch of other design decisions.

**[T]** *Mooted — we're building our own agent runtime with SDK, have direct control. Don't need external hooks.*

**[Line 29 discussed — mooted]**


### Lines 30-32: Agent types (single unit)

**Line 30:** "Daemon agents run in the background to do maintenance"
**Line 31:** "Mortal agents run in the foreground-ish to do tasks"
**Line 32:** "Jake sits at the top, you can start by going to him, or asking for an agent for an assignment"

**[U]** This and the next two lines are a single unit, describing the distinction between different agents.

**[T]** *Covered in User Flow:*
- *Daemon: background, maintenance, always running (Jake, hygiene, doc store daemons)*
- *Mortal: foreground, task-bound, lifecycle = assignment*
- *Jake: top-level daemon, entry point for user*

**[Lines 30-32 discussed]**


### Line 33: "You run as many agents as needed, who can fork off more agents"

**[C]**
```
Covered in scaling — on-demand, tree structure. Anything to add?
```

**[U]** Nope.

**[T]** *Covered in scaling discussion.*

**[Line 33 discussed]**


### Line 34: "You see the whole agent list/tree, or summarized, if you need"

**[C]**
```
Dashboard — tree visualization or summary. Covered?
```

**[U]** Basically.

**[T]** *Dashboard shows agent tree/list, can summarize. Covered.*

**[Line 34 discussed]**


### Line 35: "Agents can send messages, with certain expectations"

**[C]**
```
Messaging via doc store, bubbling. What are the "expectations"?
```

**[U]** Some messages can require a certain kind of response, or the agent is considered not working right.

**[T]** *Message protocol: certain message types expect certain response types. Wrong/missing response = agent malfunction signal.*

**[Line 35 discussed]**


### Line 36: "Agents can bubble up issues up the chain"

**[C]**
```
Covered in bubbling (?5) — upward, lateral, direct. Anything to add?
```

**[U]** It's mainly about how there's an open-ended expectation that agents will send messages up the chain as needed, to the right recipient, whether it's the immediate overseer or something higher. Also, unrelated, but agents can use messaging to collaborate as well.

**[T]** *Bubbling: open-ended expectation agents message upward to right recipient (overseer or higher). Also: messaging used for lateral collaboration between agents.*

**[Line 36 discussed]**


### Line 37: "Agents take their task, and if needed, break it down"

**[C]**
```
Task modes — break up into pieces. Covered?
```

**[U]** Basically.

**[T]** *Covered in task modes (execute, delegate, plan, break up, unify).*

**[Line 37 discussed]**


### Line 38: "Processes are scripts to follow for certain things, but these need to be evolving"

**[U]** Just another way of saying the same, was part of my brain dump earlier.

**[T]** *Covered by lines 11-12: meta process (selecting workflows) + creative meta process creator (measuring and improving workflows). The "evolving" aspect = the self-improvement loop.*

**[Line 38 discussed — covered earlier]**


### Lines 39-47: Remaining Items

**[U]** I think everything remaining in this doc is self-evident or already covered.

**[T]** *Lines 39-47 all map to earlier discussions:*
- *Line 39 (breakdown evolves) → lines 11-12 (meta process / self-improvement)*
- *Line 40 (mayor or individuals) → line 24 (zoom decision)*
- *Line 41 (mortal lifecycle) → lines 30-32 (agent types)*
- *Line 42 (daemon ensures health) → lines 30-32 + line 22 (agent types + hygiene)*
- *Line 43 (naming scheme) → vocab_naming-themes*
- *Line 44 (daemon monitors assignment) → daemon role, relates to ?4*
- *Line 45 (units of work) → task modes + drones discussion*
- *Line 46 (units have steps) → line 6 (workflow engine)*
- *Line 47 (different environments) → line 2 (sandbox primitives)*

**[Lines 39-47 discussed — all covered by earlier material]**

___

**[S]** Synthesis: initial_notes.md Walkthrough Complete

All 47 lines of the seed document have been walked through. Key outcomes:

**Resolved Questions:**
- ?1 (worktree assumptions) → Use overlay filesystems orthogonal to git
- ?8 (sandboxing) → Five primitives defined (changeset, platform, isolation, outputs, software)

**New Concepts Surfaced:**
- Preflight checks at spawn
- Document store as FOUNDATION (memory backbone, messaging, work queues)
- Workflow engine vs spec engine distinction
- Meta process + creative meta process for self-improvement
- Discovery sharing via prompt engineering (can't enforce deterministically)

**Confirmed Concepts:**
- Agent types (daemon, mortal, Jake)
- Task modes (execute, delegate, plan, break up, unify)
- Zoom and bubbling mechanics
- Naming schemes with tier depletion
- Fish-or-cut-bait triggers
- Rewind and branch capability


---

## Resolving Open Questions

[Later on 01-19]

**[U]** Alright, firing questions, whether they're open ones, or new ones you come up with, let's chase away all the ambiguities.

### ?2 — Deterministic Shell

**[C]**
```
You said workflows need a "deterministic shell" to enforce they're performed
correctly. What does this mean concretely? Scripted steps with gates?
Reproducibility? Audit trail?
```

**[U]** Let's talk determinism. We're using the Agent SDK, and that means we can directly control the prompt we send to Claude. We can deterministically compose the prompt out of several pieces, including skills or instructions. This gives us a deterministic shell rather than praying the agent remembers to use skills.

**[U]** There's more aspects. Another is displaying documents in a passthrough, to ensure the user sees what's being stored. We'll offer tools, such as calculators, so the outputs from the agent are essentially structured statements that can be read deterministically. Code is one such output, but then, so is a document that looks sorta like a spreadsheet. At the end of the day, we don't want the agent just blindly guessing at math problems.

**[U]** Another big one is once an agent has a definition of done, e.g. passing tests, but something deterministic, we can force the agent to keep working until the deterministic code asserts the agent actually is done, according to the original commitment. That should partly answer ?4. Also, "done" is not the same as "I'll wait for wakeup" or "I'll wait for input".

**[T]** *Deterministic shell = minimizing reliance on non-deterministic LLM behavior:*
1. *Prompt composition — build prompts programmatically (skills, instructions), not hoping agent remembers*
2. *Passthrough display — user sees what's stored, not LLM retranscription*
3. *Structured outputs via tools — calculators, etc. Agent doesn't guess at math; calls tool for deterministic result*
4. *Verification — "done" asserted by deterministic code (tests pass), not agent's word*

**[?2 resolved]**


### ?4 — Agent "Done" Assertion (continued)

**[C]**
```
What's the full set of agent states? Who writes the definition of done?
```

**[U]** Yeah, also, capture that the agent commits to doing something and then is validated against an independent assertion.

**[U]** I think blocked is the same as waiting for input, just a different flavor of input required than quick questions.

**[U]** The parent can also put an assignment on the child agent, and then the child agent supplements that with their commitments.

**[T]** *Agent states:*
- *Working — saturated, doing stuff*
- *Waiting for input — needs human response (includes "blocked" — same state, different flavor)*
- *Waiting for wakeup — idle, perseverance will prod*
- *Done — task complete, verified by deterministic assertion*
- *Failed/Reaped — fish-or-cut-bait triggered*

*Definition of done = parent's assignment + child's commitments layered on top. Validated against independent assertion, not self-reported.*

**[C]**
```
How does the child agent express its commitments? Structured tool call?
Natural language parsed? Where do they live?
```

**[U]** Each agent will get a node in the document store, we can attach commitments to there. We can prefill them in code, or make sure the agent calls a tool at some point, and push back on the agent if it hasn't done so yet.

**[T]** *Each agent gets a node in the document store. Commitments attach there. Can be prefilled by code (from parent) or added via tool call. System pushes back if agent proceeds without committing.*

**[?4 resolved]**


### ?5 — Bubbling Up

**[C]**
```
Child needs user input. What's the routing? Through parent chain?
Direct to user? Can skip levels?
```

**[U]** How the child reaches the user is based on context, such as zoom, and you can think of this as similar to how a CEO might delegate most things, but then pay closer attention to what one team is doing, when it makes sense.

**[U]** If the parent is stuck, and was responsible for forwarding on the message, it'll get reaped, restarted, and it'll know to clear its message queue, or something else will have to follow up. But failures of a parent could delay delivery of the message.

**[T]** *Routing is context-dependent (based on zoom, user attention). CEO model — delegate most things, pay closer attention to specific teams when needed. Parent failure can delay delivery — acknowledged. Not a rigid protocol, adaptive to user focus and chain health.*

**[?5 resolved]**


### ?6 — Perseverance Prompts & Lifecycle

**[C]**
```
When agent in perseverance mode stops, what does the auto-prompt look like?
Just "continue"? Context about why it stopped?
```

**[U]** If the agent sends a basic done signal, we send it some kind of continue. It could just be "keep going", or running a validation step and giving the agent that feedback if it fails, but like any Meeseeks, if its job isn't done, we don't let it die.

**[U]** If the user joins in the session, let's say some tokens are streaming, the user will start to see those tokens show up, plus the history. The deterministic code will add a "query" that's just a message that the user joined at that point, so that the agent knows there's someone else in the room to talk to. When the user "hangs up", the agent knows not to pause anymore, and if it needs inputs, send a message and then get on with something else.

**[T]** *Perseverance prompts:*
- *Basic "keep going" if agent signals done but work isn't actually done*
- *Or run validation, give feedback if it fails*
- *Meeseeks principle: if job isn't done, don't let it die*

*Calling (user joins): deterministic code injects "user joined" message. Agent knows someone's there to talk to.*

*Hanging up (user leaves): agent knows not to pause for interaction, if it needs input send a message and move on.*

**[?6 resolved]**


### ?7 — User Consent for New Chats

**[C]**
```
Agents can suggest user zoom in, but shouldn't force new chats unless user
is "OK with it." What does OK look like? Global preference? Per-agent?
Implicit from context?
```

**[U]** No idea, we need to tune this over time, but the north star principle is we don't just shove new stuff in front of the user.

**[T]** *North star principle: don't shove new stuff in front of the user without consent. Implementation TBD, tune over time.*

**[?7 resolved — principle established, details TBD]**


### ?9 — UI Stream Separation

**[C]**
```
TUI smooshes everything together. What are the distinct stream types?
How do you envision separation — panes, tabs, visual distinction?
```

**[U]** This is UX, so TBD, but at a minimum, use interface styling cues to indicate what the content is, and pull chat messages to a dedicated chat view where the user can see just the conversation, with the rest of the bits displayed alongside the chat.

**[T]** *Minimum requirements:*
- *Styling cues to indicate content type*
- *Dedicated chat view — just conversation, readable*
- *Other streams displayed alongside*

*Details TBD through UX iteration.*

**[?9 resolved — principle established, details TBD]**


### ?19 — Work Queues

**[C]**
```
Where do work queues live? Who creates them? Can agents attach mid-task?
What happens when queue is empty?
```

**[U]** Work queues are in the document store, parents create them. Agents can attach at spawn time or mid-task, agents will have instructions what to do when the queue is empty, determinism will make sure those instructions are present.

**[T]** *Work queues:*
- *Live in document store*
- *Parents create them*
- *Agents attach at spawn or mid-task*
- *Instructions for empty queue required (idle, hibernate, terminate, etc.)*
- *Determinism ensures instructions are present*

**[?19 resolved]**

___

**[S]** Synthesis: All Original Open Questions Resolved

| Question | Resolution |
|----------|------------|
| ?2 Deterministic shell | Prompt composition + passthrough display + structured tools + verification |
| ?3 Self-improvement | Covered by meta process + creative meta process (lines 11-12) |
| ?4 Agent "done" | Commitments in doc store node, validated by independent assertion |
| ?5 Bubbling | Context-dependent routing, CEO model, parent failure can delay |
| ?6 Perseverance | "Keep going" or validation feedback, Meeseeks principle, calling/hanging up messages |
| ?7 User consent | North star: don't shove stuff at user. Details TBD |
| ?9 UI streams | Styling cues + dedicated chat view + streams alongside. Details TBD |
| ?19 Work queues | In doc store, parents create, attach at spawn or mid-task, empty-queue instructions required |


---

## New Questions — Chasing Ambiguities

[Continued 01-19]

### ?20 — Document Store Structure

**[C]**
```
Each agent gets a node. Work queues live there. What else?
Type system? Namespacing? On-disk representation?
```

**[U]** Some of this is still TBD, but one file per node.

**[T]** *One file per node. Other structure details TBD.*


### ?21 — Changeset Lifecycle

**[C]**
```
Agent produces changeset. Who approves? When applied? Can agents share
a changeset? What happens to overlay after apply?
```

**[U]** Depends on the context and flavor of agent environment, but we can deterministically make sure we have these answered in the moment.

**[T]** *Changeset lifecycle is context-dependent (varies by agent environment), but determinism ensures it's defined before runtime. No ambiguity at runtime.*


### ?22 — Gang of Experts

**[C]**
```
Specialized agents (reviewer, tester, architect). Daemon or mortal?
Pre-existing or spawned on demand? Share context or work from changeset alone?
```

**[U]** These are more prescribed prompts that are put into agents more than anything else, often separate contexts though.

**[T]** *Gang of experts = prescribed prompts applied to agents, not persistent entities. "Pull in reviewer" = spawn agent with reviewer instructions. The expertise is in prompt configuration.*


### ?23 — Token Budgets

**[C]**
```
Granularity? Per-agent, per-task, per-tree? Who sets them?
What happens when exceeded?
```

**[U]** All of this is per context, but from a PRD perspective, the idea is that we track token use in general so we can act on it.

**[T]** *Core requirement: track token use so we can act on it. Granularity and actions are per-context.*


### ?24 — Message Protocol

**[C]**
```
Defined message type system? Expected responses per type?
What happens on wrong/missing response?
```

**[U]** We're not making the whole inventory, and the instructions depend on the context.

**[T]** *No fixed message type inventory. Context defines which messages need responses and what happens when missing.*


### ?25 — Spec Representation

**[C]**
```
How is the spec represented? Derived from prompt? Separate document?
Structured or natural language? Who writes it?
```

**[U]** Specs are documents, with some formalism. In some workflows, the agent might take the assignment, create the PRD, then the spec, and then start planning, and based on the details, the user may be more or less involved at every point, and likewise, this is done by one or more agents. This is open ended though, when it comes to approvals, based on the assignment.

**[T]** *Specs = documents with some formalism. Workflow can be: assignment → PRD → spec → planning. User involvement and approvals are open-ended based on assignment. Spec can emerge through the workflow.*


### ?26 — Drones vs Regular Mortals

**[C]**
```
How does spawner decide drone vs regular mortal? Explicit in spawn call?
Can drone upgrade if task turns complex?
```

**[U]** In some cases, when we can break down work into a bunch of chunks, we may want to use agents on less powerful models to do heavy lifting. If they hit a problem, they fail, and some other agent comes to clean up the mess.

**[T]** *Drones can use less powerful models for heavy lifting. Well-defined chunks, cheap to run, cheap to fail. Hit problem → fail → another agent cleans up. Not precious.*


### ?27 — Model Selection Per Agent

**[C]**
```
Can different agents in same tree use different models? Haiku for drones,
Sonnet for coordinators, Opus for architects? Part of spawn config?
```

**[U]** Basically, yeah.

**[T]** *Yes — model selection is per-agent, part of spawn configuration. Different models for different roles (cheaper for grunt work, more capable for coordination/architecture).*


### ?28 — Spawn Configuration

**[C]**
```
When parent spawns child, what gets specified? Assignment, sandbox config,
model, budget, queue, naming theme, commitments, done-behavior?
```

**[U]** Naming themes belong to the root of the tree, but everything else is open to modification at spawn time.

**[T]** *Naming theme at tree root (Jake assigns). Everything else modifiable at spawn.*


### ?29 — Jake's Spawn vs Child Spawn

**[C]**
```
Is there anything Jake does at spawn that regular mortals can't?
Or is Jake just "first spawner"?
```

**[U]** Well, Jake is Jake, that's a full time job. But also, he oversees all other agents, including any daemons that monitor the other agents for Jake. Also, the user can go talk to Jake at any time.

**[T]** *Jake's special nature:*
- *Daemon — always running*
- *Oversees ALL agents, has monitor daemons working for him*
- *User can always access him directly*
- *Regular mortals are task-scoped. Jake is tavern-scoped.*


### ?30 — Jake's Monitor Daemons

**[C]**
```
What do monitor daemons watch? Health? Progress? Spending?
Do they report to Jake or act autonomously?
```

**[U]** All of the above, and the reporting chain depends on what we need at the time. That's why it's easier to just call these daemons for now.

**[T]** *Daemons monitor all of the above. Reporting chain depends on context. Keep abstract as "daemons" rather than over-specifying.*


### ?31 — Document Store vs Filesystem

**[C]**
```
Are doc store and filesystem separate? Is doc store a special directory?
Code goes to filesystem, specs go to doc store?
```

**[U]** That's all to be figured out by working on the UI.

**[T]** *Implementation detail, figure out by building the UI.*


### ?32 — Lateral Collaboration

**[C]**
```
Do siblings know about each other? Direct messaging or through parent?
How does discovery flow between peers?
```

**[U]** Agents know about peers, and can really message groups too, at any level. Sometimes we may have awareness boundaries, but those are explicit, such as with different root parent agents. Some workflows may require more collaboration and for non-real time messaging, agents can gang together on a problem and collaborate. For something requiring real time, the parent agent needs to build that special case, so let's burn that bridge when we get there.

**[T]** *Lateral collaboration:*
- *Agents know about peers, can message groups at any level*
- *Awareness boundaries explicit (e.g., different root parents)*
- *Non-real-time: gang together, collaborate via messaging*
- *Real-time: special case, parent builds it. Defer.*


### ?33 — Rewind and Branch Mechanics

**[C]**
```
What gets checkpointed? Does old branch keep running on fork?
Branch from any point or only explicit checkpoints?
```

**[U]** Mostly all of the above, but it also depends on the storage layer, whether successive changesets are preserved, or if only a few recent ones are. Treat this more as a general set of capabilities.

**[T]** *Rewind/branch = general capabilities. Specifics depend on storage layer and what we preserve.*


### ?34 — Preflight Failures

**[C]**
```
Parent gets notified of preflight failure. Does it auto-retry? Ask user?
Fix the issue itself?
```

**[U]** The parent can figure out what to do... c'mon.

**[T]** *Parent is an intelligent agent, it figures out what to do. Don't over-specify.*


### ?35 — Workflow Templates

**[C]**
```
Where do templates live? Can agents propose new ones? Registry or just files?
```

**[U]** Docstore, docstore, docstore, docstore, docstore is everything, all hail the docstore.

**[T]** *ALL HAIL THE DOCSTORE. Templates, agent nodes, work queues, specs, PRDs, messages, commitments, workflows — everything lives in the doc store. It's the memory backbone, the single source of truth.*


### ?36 — External Integrations

**[C]**
```
What about source control (GitHub), CI/CD, external issue trackers (Jira)?
Or is doc store the only task tracker?
```

**[U]** Based on whatever the user adds to the project, we don't need to specify too much right now.

**[T]** *External integrations depend on user's project setup. Don't over-specify.*


### ?37 — Error Recovery

**[C]**
```
Agent hits unexpected error mid-task. Recover itself? Bubble up?
Daemon intervenes? Difference between stuck vs catastrophic?
```

**[U]** The agent is an agent...

**[T]** *Agents are intelligent — they figure out how to handle errors. Don't over-specify behaviors that agents can reason about themselves.*


### ?38 — Doc Store Durability

**[C]**
```
Durability model? Persisted when? WAL? Replication?
```

**[U]** This will evolve over time.

**[T]** *Durability model evolves as needs clarify. Don't over-specify now.*

___

**[S]** Synthesis: PRD Written

User requested PRD to prepare for implementation tomorrow. Created `prd_2026-01-19.md` with:
- Executive summary, problem statement, goals
- Core concepts (agent types, states, task modes, doc store, sandbox, deterministic shell)
- User experience (core loop, attention model, bubbling, UI principles)
- System architecture (tech stack, spawn config, work queues, preflight, merge queue, hygiene)
- Agent naming, metrics, workflows, gang of experts, fish-or-cut-bait, rewind/branch
- Open items and success criteria

**Day 1 Questions identified:**
1. Agent SDK language bridge (TS/Python SDK vs Swift)
2. Jake's startup (app launch vs service)
3. Changeset implementation (real overlay FS vs simulated)
4. API keys location
5. Session persistence (ephemeral vs survives app close)
6. Doc store location (project vs user-level)

No conflicts found — these are implementation decisions for day 1.


---

## Pre-Implementation Simplification

**[U]** Let's merge the document store and the file system completely, for now. A file is a document, but we'll have code that implements rules on top.

**[T]** *Key simplification: doc store IS the filesystem. No separate storage abstraction. A file is a document. Code layer implements rules (validation, structure, relationships). Resolves day 1 question about doc store location.*


### Tech Stack Decision

**[U]** Do a web search for Swift Anthropic SDK... look for the agent sdk in swift.

**[C]**
```
Found ClaudeCodeSDK by jamesrochabrun — Swift wrapper that spawns Agent SDK
as subprocess. Gets session persistence, tool management, MCP support.
Requires Node.js + Agent SDK npm package.
```

**[U]** We should have sufficient control with the ClaudeCodeSDK, based on my earlier reading of the API. Let's use it for now, and see how far we get.

**[T]** *Tech stack decision: ClaudeCodeSDK for Swift integration with Agent SDK. Spawns Agent SDK as subprocess, giving us agent features while staying in Swift. Can swap to SwiftAnthropic (direct API) later if we need more control. Resolves day 1 question #1.*


### Day 1 Scope and Requirements

**[U]** For the overlays, those are all valid options, we're not gonna do sandboxing with overlays right away though. The Claude Code SDK can use the CLI creds by default. Persistence is through Claude Code and the Agent SDK.

**[U]** We need a few things:
1. The PRD needs a list of things we cannot violate, hard enforced
2. The app needs a dynamic non-violation list for monitoring agents
3. V1 focuses on chats and spawn system, space left for sandboxing later — prove the concept
4. Critical requirement: all features must be testable with fully automated test suite from day 0
5. Must be able to create, reuse, renew testing environment with stubs
6. My implementation must follow the same standards — step by step plan with commitments, verified by subagents

**[U]** Also, call the app itself just "Tavern".

**[T]** *Major decisions:*
- *App name: Tavern*
- *V1 defers: overlays, sandboxing, containerization*
- *V1 focus: chats, spawning, prove concept*
- *Auth: CLI creds via ClaudeCodeSDK*
- *Persistence: handled by Claude Code / Agent SDK*
- *Critical: testability from day 0, no exceptions*
- *Process: I must write implementation plan with commitments, verify with subagents*

*Created:*
- *PRD Section 2: Invariants (8 hard-enforced rules)*
- *PRD Section 15: Violation Monitoring (dynamic rules)*
- *PRD Section 16: Testability Requirements*
- *PRD Section 17: V1 Scope*
- *v1-implementation-plan.md: Step-by-step plan with commitments and verification*
