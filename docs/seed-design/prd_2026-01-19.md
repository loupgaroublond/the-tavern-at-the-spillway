# Product Requirements Document: Tavern

**Version:** 1.2
**Date:** 2026-01-21
**Status:** Ready for implementation


## 1. Executive Summary

**Tavern** is a multi-agent orchestration framework built on the Claude Agent SDK (via ClaudeCodeSDK). It enables users to manage complex software development tasks through a hierarchy of AI agents, with Jake (The Proprietor) as the always-available top-level coordinator.

The system prioritizes:
- **User control over attention** — agents work autonomously but surface questions intelligently
- **Deterministic shell around non-deterministic agents** — prompt composition, structured tools, and independent verification
- **The Document Store as memory backbone** — single source of truth for everything


## 2. Invariants (Hard-Enforced)

These rules cannot be violated under any circumstances:

1. **Test suite must pass before any feature ships** — No exceptions. If tests don't exist for a feature, write them first.

2. **Every feature must be testable** — If you can't test it automatically, redesign it until you can.

3. **Commitments must be verified independently** — Agent says "done" means nothing. Deterministic assertion verifies.

4. **User attention is sacred** — Never force new content on user without consent. Surface questions, don't interrupt.

5. **Doc store is source of truth** — If it's not in a file, it doesn't exist. No in-memory-only state that matters.

6. **Agents cannot modify their own invariants** — The rules layer is outside agent control.

7. **Failures must be visible** — Silent failures are bugs. If something breaks, it must surface.

8. **Original project files are protected** — Until changeset is explicitly applied, original files are untouched.


## 3. Problem Statement

Current AI coding assistants have limitations:

1. **Single-threaded interaction** — user can only work with one agent at a time, waiting around
2. **No orchestration** — can't delegate, parallelize, or coordinate multiple agents
3. **Opaque execution** — everything smooshed together in TUI, hard to follow
4. **No verification** — agent says "done" and you trust it
5. **Worktree assumptions** — existing sandboxing tools assume single-repo, single-worktree patterns
6. **Hook-based control** — constrained to pre/post hooks rather than direct programmatic control
7. **No self-improvement** — no measurement or evolution of workflows


## 3. Goals

**Must Have:**
- Multiple agents working in parallel on a single project
- User can engage with any agent at any depth while others work in background
- Autonomous operation with intelligent question surfacing
- Deterministic verification of agent commitments
- Sandbox isolation orthogonal to git/worktrees
- Document store as central nervous system

**Should Have:**
- Workflow templates (rule of 5, verification layers)
- Token tracking and budget awareness
- Rewind and branch capability
- Merge queue for coordinated changesets

**Non-Goals (for v1):**
- Real-time multi-agent collaboration (defer until needed)
- External issue tracker integration (user adds as needed)
- Distributed/replicated doc store (single machine first)


## 4. Core Concepts


### 4.1 Agent Types

| Type | Lifecycle | Purpose |
|------|-----------|---------|
| **Jake** | Daemon (always running) | Top-level coordinator, tavern-scoped, oversees all agents |
| **Mortal** | Task-scoped | Handles assignments, can spawn children, waits for input |
| **Drone** | Single task | Meeseeks-style, one task then terminate, cheap models, cheap to fail |
| **Monitor Daemons** | Background | Work for Jake, monitor health/progress/spending |


### 4.2 Agent States

```
Working ──────► Waiting for Input ──────► Done
    │                   │                   ▲
    │                   ▼                   │
    └──────► Waiting for Wakeup ───────────┘
                        │
                        ▼
                  Failed/Reaped
```

- **Working** — Saturated, doing stuff
- **Waiting for Input** — Needs human response (includes "blocked" — same state, different flavor)
- **Waiting for Wakeup** — Idle, perseverance mode will prod
- **Done** — Task complete, verified by deterministic assertion
- **Failed/Reaped** — Fish-or-cut-bait triggered


### 4.3 Task Modes

Agents can bounce between these modes:
1. **Execute** — Do the work directly
2. **Delegate** — Pass to new agent
3. **Plan** — Think more before acting
4. **Break up** — Split into pieces, assign children
5. **Unify** — Combine work from delegated agents


### 4.4 Operating Modes

- **Chat mode** — Open chat window, pings user when agent stops
- **Perseverance mode** — Background thread, system auto-prompts to continue, agent must explicitly request user attention


### 4.5 The Document Store

**The doc store IS the filesystem.** A file is a document. One file per node.

There is no separate "doc store" abstraction — just files on disk with code that implements rules on top (validation, structure, relationships, etc.).

Contains:
- Agent nodes (with commitments attached)
- Work queues
- Specs and PRDs
- Messages
- Workflow templates
- Code files
- Everything else

Principle: If it's a file, it's a document. The "doc store" is just the rules layer.


### 4.6 Sandbox Primitives

Five orthogonal primitives, mix-and-match per agent:

1. **Changeset** — Overlay filesystem on project root. Writes go to overlay. Changeset = diff. Protects original.
2. **Platform** — Where agent runs (Mac, container, cloud, hybrid)
3. **Isolation** — VMs, containers, OS sandboxes. Agent can trash everything, reap and restart.
4. **Outputs** — Network access control
5. **Software** — OS choice (macOS, Linux, FreeBSD)

Source control is orthogonal — changesets work across multiple repos.


### 4.7 Deterministic Shell

Minimizing reliance on non-deterministic LLM behavior:

1. **Prompt composition** — Build prompts programmatically from skills, instructions. Don't hope agent remembers.
2. **Passthrough display** — User sees what's stored, not LLM retranscription.
3. **Structured outputs via tools** — Calculators, etc. Agent doesn't guess at math.
4. **Verification** — "Done" asserted by deterministic code (tests pass), not agent's word.

**Commitment flow:**
- Parent assigns task
- Child supplements with its own commitments (stored in doc store node)
- Child works
- Independent assertion verifies commitments were met
- Only then is agent "done"


## 5. User Experience


### 5.1 The Core Loop

1. User opens project directory in UI
2. Fresh project: just Jake's chat box
3. User describes what they need
4. Jake spawns a mortal agent to handle it, stays free for next thing
5. Mortal agent lifecycle = lifecycle of completing that task
6. Task appears as both todo item AND chat interface
7. Dashboard shows all open tasks; user can drill into any agent


### 5.2 Attention Model

- User sees tabs/UX for agents they're engaged with
- Notification bubbles when agents have questions
- "Whack-a-mole" style jumping between conversations
- Can zoom in on any agent at any depth
- Zooming in on busy agent: see "cogitating" status, can steer/interrupt/wait

**Calling and Hanging Up:**
- User joins session → deterministic code injects "user joined" message → agent knows someone's there
- User leaves → agent knows not to pause for interaction, sends messages and moves on


### 5.3 Bubbling

Routing is context-dependent, based on zoom level and user attention. CEO model: delegate most things, pay closer attention to specific teams when needed.

- Can be upward (child → parent → grandparent → user)
- Can be lateral (siblings collaborating)
- Can be direct to user (with oversight)
- Parent failure can delay delivery (acknowledged)


### 5.4 UI Principles

**North star:** Don't shove new stuff in front of the user without consent.

**Stream separation:**
- Styling cues to indicate content type (thinking vs tool use vs code vs etc.)
- Dedicated chat view — just the conversation, readable
- Other streams displayed alongside

**Details:** TBD through building.


### 5.5 Question Triage

- Questions classified as quick vs deep
- Notifications convey complexity so user knows what they're getting into
- Parent agent chooses notification approach for its children (popup vs periodic summary)


## 6. System Architecture


### 6.1 Tech Stack

- **Agent Runtime:** [ClaudeCodeSDK](https://github.com/jamesrochabrun/ClaudeCodeSDK) — Swift wrapper that spawns Agent SDK as subprocess
- **Primary Language:** Swift 6.0+
- **Platform:** macOS 13+
- **GUI:** SwiftUI (Mac app primary)
- **Dependencies:** Node.js + @anthropic-ai/claude-agent-sdk (for Agent SDK backend)
- **Also:** GUI-less framework core, TUI equivalent


### 6.2 Agent Spawn Configuration

When spawning a child, parent can specify:
- Assignment (what to do)
- Sandbox config (which primitives, how configured)
- Model selection (Haiku for drones, Sonnet for coordinators, Opus for architects)
- Token budget
- Work queue attachment
- Commitments to prefill
- What to do when done (terminate, wait, check queue)

**Naming theme** belongs to tree root (Jake assigns when starting mortal tree). Children use same theme.


### 6.3 Work Queues

- Live in document store
- Parents create them
- Agents attach at spawn or mid-task
- Agents have instructions for empty queue (idle, hibernate, terminate, etc.)
- Determinism ensures instructions are present


### 6.4 Preflight Checks

At spawn, before autonomous work:
- Sandbox configured correctly
- Has access to required resources
- No permissions prompts expected
- External accounts (AWS, etc.) authenticated

Fail = agent doesn't start, parent notified with reason.


### 6.5 Merge Queue

- Applies to changesets and source repos
- Agents queue up, see what's ahead
- Refine against predictable target
- Serialized merges, fewer conflicts


### 6.6 Hygiene

Daemons handle cleanup of:
- Dead agents
- Old changesets
- Stale overlays
- Orphaned workflows, documents, resources


## 7. Agent Naming

Jake assigns a naming theme to each mortal agent tree. Names have familial resemblance so users intuit relationships.

**Principles:**
- Global uniqueness — every mortal agent has unique name system-wide
- Tier depletion — exhaust less silly names before breaking out sillier ones
- Easter eggs — some themes reveal jokes only with enough children

**Example themes:** LOTR, Rick and Morty, Santa's reindeer (with escalating tiers), Docker-style adjective_scientist combos, Jewish figures, etc.

See `vocab_naming-themes_2026-01-19-1144.md` for full list.


## 8. Metrics

**Time Categories:**
- Token time — waiting for LLM API responses
- Tool time — tool execution (tests, builds)
- Wall clock time — total elapsed
- Throttle time — excluded from metrics (API limits, rate limiting)

**Agent Metrics:**
- Utilization = Token time / Wall clock
- Saturation = (Token + Tool time) / Wall clock
- Agent wait time = time since stopped

**Human Metrics:**
- Human wait time = idle time between things needing attention (ideally zero)
- Context switching load = dashboard metric, not a warning

**Amplification:**
- Primary measure: count of saturated agents running concurrently
- High amplification = many agents productively working while human focuses elsewhere


## 9. Workflows


### 9.1 Starter Templates

- **Rule of 5** — 5 agent passes over single output from initial prompt
- **Verification layers** — Progressive gates: linting → code structure → architecture → performance

User can modify. Agents can propose new templates (creative meta process).


### 9.2 Meta Process

Decision layer for selecting which workflows/tools to use for a given task. Goal: improve overall performance through measurement and learning.


### 9.3 Discovery Sharing

Agents (even drones) prompted to notice oddities and share them via messaging, even while continuing main task. Can't enforce via deterministic hook — relies on prompt engineering encouraging curiosity + social behavior.


## 10. Gang of Experts

Specialized prompts applied to agents (not persistent entities):
- Reviewer
- Tester
- Architect
- etc.

"Pull in the reviewer" = spawn agent with reviewer instructions. User can customize.


## 11. Fish or Cut Bait

Triggers to kill and restart rather than continue:
- Token budget exceeded
- Changeset is totally wrong
- Agent spinning
- Whole gang going down wrong path


## 12. Rewind and Branch

General capability to checkpoint, tweak prompt, fork new timeline. Works at both agent and changeset level. Specifics depend on storage layer and what we preserve.


## 13. Open Items / TBD

These will be figured out through building:

| Area | Status |
|------|--------|
| Doc store file structure/namespacing | One file per node, rest TBD |
| ~~Doc store vs filesystem boundary~~ | RESOLVED: They're the same. File = document. |
| Doc store durability model | Evolves over time |
| External integrations | User adds as needed |
| Message protocol specifics | Context-dependent |
| Changeset lifecycle specifics | Per environment flavor |
| User consent UX for new chats | Principle set, details TBD |
| UI stream separation details | Principle set, details TBD |
| Real-time agent collaboration | Burn bridge when we get there |
| Standard agent tool set | Emerges through building |
| Prompt composition structure | Emerges through building |
| Multi-project / Jake-per-project | Emerges through building |


## 14. Day 1 Questions

Decisions needed before/during initial implementation:

**1. Agent SDK Language Bridge** — RESOLVED
- Using [ClaudeCodeSDK](https://github.com/jamesrochabrun/ClaudeCodeSDK) by jamesrochabrun
- Swift wrapper that spawns Agent SDK as subprocess
- Gets Agent SDK features (session persistence, tool management, MCP) with Swift integration
- Requires Node.js + Agent SDK npm package installed

**2. Jake's Startup** — RESOLVED (v1)
- Jake starts when app opens, stops when app closes
- Future: could be system service

**3. Changeset Implementation** — DEFERRED
- Not doing overlays for v1
- Agents work on actual files for now
- Architecture leaves space for overlays later

**4. API Keys / Auth** — RESOLVED
- ClaudeCodeSDK uses CLI credentials by default
- No additional auth setup needed

**5. Session Persistence** — RESOLVED
- Handled by Claude Code and Agent SDK
- ClaudeCodeSDK has session persistence built in

**6. Doc Store Location** — RESOLVED
- Doc store IS the filesystem
- A file is a document
- Code implements rules on top (validation, structure, relationships)
- No separate storage abstraction for v1


## 15. Violation Monitoring

Beyond static invariants, the app maintains a **dynamic violation list** — rules that can be configured per-project or per-agent. Agents are monitored for violations of these rules.

**Examples of configurable violations:**
- Modifying files outside designated directories
- Exceeding token budgets
- Spawning more than N children
- Accessing network when disallowed
- Running commands on blocklist

**When violation detected:**
- Log the violation
- Notify parent agent and/or user
- Optionally: pause agent, reap agent, or allow with warning

**Implementation:** Rules layer checks agent actions against violation list. Agents cannot modify their own violation rules.


## 16. Testability Requirements

**This is non-negotiable for v1.**

1. **Fully automated test suite from day 0** — Tests exist before or alongside features, never after.

2. **Every feature must be tested** — Adding a feature means adding tests. No exceptions.

3. **Test suite catches regressions** — If you accidentally break something while working on another feature, tests catch it.

4. **Testing environment is reproducible** — Can create, reuse, and renew test environment with stubs.

5. **Tests run fast enough to not block flow** — If tests are too slow, you'll skip them. Keep them fast.

6. **Test stubs for external dependencies** — Claude API, filesystem, etc. must be stubbable.

7. **Stress testing is mandatory** — Performance tests must:
   - Generate synthetic load (large message histories, many agents, deep compaction chains)
   - Measure responsiveness under load
   - Verify isolation (heavy background work doesn't impact UI metrics)
   - Establish baselines and catch regressions
   - Specific thresholds TBD after initial testing identifies natural limits

**Why this matters:** Tavern will change rapidly while being used. Without tests, every change risks breaking something. With tests, you can move fast and know things work.


## 17. V1 Scope

**V1 is a proof of concept.** Focus on core flow, leave space for future capabilities.

**V1 Must Have:**
- User can open project and chat with Jake
- Jake can spawn mortal agents
- User can see agent list and switch between chats
- Basic spawn configuration (assignment, model selection)
- Agents can complete tasks and report done
- Commitments verified by assertion
- Full test suite for all of the above

**V1 Deferred:**
- Sandboxing with overlays (space left in architecture)
- Containerization / cloud agents
- Changesets (agents work on actual files for now)
- Merge queue
- Drones / work queues
- Workflow templates
- Metrics dashboard
- Rewind and branch

**V1 Principle:** Get chats and spawning working correctly, prove the concept, then layer on capabilities.


## 18. Development Standards

These standards apply to all code in the project — both human-written and AI-generated. Claude must adhere to these standards when working on this codebase.


### 18.1 Logging Standards

All new code must be instrumented with appropriate logging.

**What to log:**
- Entry/exit for async operations (API calls, SDK interactions)
- State transitions (agent state changes, UI state changes)
- Errors with full context (what operation, what parameters, what failed)
- Key events (session creation, agent spawn/dismiss, message send/receive)

**Log levels:**
- `.debug` — Verbose information for development (stripped from release builds)
- `.info` — Key events that help understand app flow
- `.error` — Failures that need attention

**Logging system:** Use `os.log` via `TavernLogger` categories:
- `TavernLogger.agents` — Agent lifecycle, state transitions
- `TavernLogger.chat` — Message flow, conversation state
- `TavernLogger.coordination` — Spawn, dismiss, selection
- `TavernLogger.claude` — SDK calls, API interactions

**Principle:** Debug builds must produce enough logs to diagnose issues without screenshots, videos, or human reproduction steps.


### 18.2 Testing Standards

Every new feature requires tests. No exceptions.

**Test requirements:**
- Unit tests for all new logic
- Integration tests for cross-component behavior
- Tests must be automated — no human interaction required
- Tests must run in CI without special setup

**Test organization:**
- `TavernCoreTests/` — Fast unit tests (run during development)
- `TavernTests/` — Integration tests
- `TavernStressTests/` — Performance/stress tests (run before releases)


### 18.3 Stress Testing Standards

Changes touching scale, concurrency, or data structures require stress test coverage.

**What requires stress tests:**
- Message history handling
- Agent spawning/dismissal at scale
- Concurrent operations
- Memory-intensive operations

**When to run stress tests:**
- End of development cycle
- Before releases
- After significant refactoring
- When performance issues are suspected

**See:** `docs/stress-testing.md` for detailed test descriptions and baseline numbers.


## 19. Success Criteria

**v1 is successful if:**
1. User can open a project and talk to Jake
2. Jake can spawn mortal agents that work autonomously
3. User can see dashboard of all agents and zoom into any
4. Agents can spawn children and coordinate via doc store
5. Deterministic verification works (agent commits, system checks)
6. Changesets protect original project from agent writes
7. User spends more time directing than waiting

**Future indicators:**
- High amplification factor (many saturated agents, one human)
- Workflows improving through measurement
- Users entertained by agent names and cogitation verbs


## 20. Performance Requirements

### Principle: Perception-Bounded Performance

The app must remain responsive under all conditions. "Fast" is defined by user perception, not raw metrics. Heavy operations may take time, but they must never degrade unrelated work.


### Core Rules

1. **Isolation** — No operation may impact unrelated parts of the app. A search over massive history cannot cause scroll jank. A runaway agent cannot freeze the coordinator. Loading one session cannot block viewing another.

2. **Responsiveness over speed** — UI must always respond to user input. If an operation takes time, show appropriate feedback (spinner, progress, skeleton). The window appears immediately; content fills in as available.

3. **Perception boundaries** — Zones where the user expects delay as natural. Examples: a thorough search across massive history, scrolling back through a long discussion, initial load of a very old session. These are places where the user's mental model includes "this might take a moment." We can lean into those expectations with appropriate feedback (spinners, progressive loading). Conversely: anywhere the user *doesn't* expect delay, there must be none. Typing, clicking buttons, switching tabs, viewing current content — these must feel instant regardless of background state. Discovered and documented as development proceeds.

4. **Scale independence** — Performance of viewing current content must not degrade as history grows. Thousands of messages, hundreds of agents, multiple compactions — the visible slice stays fast.


### Cancellation

Context-dependent. Design each case explicitly.


### RAM Budget

No fixed target. If the app causes system-wide slowdown or memory pressure warnings, that's a bug. Design data structures to avoid holding unbounded data in memory when not needed.


---

*All hail the docstore.*
